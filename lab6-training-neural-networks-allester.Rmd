---
title: "training-nueral-networks"
author: "allester"
date: '2022-11-02'
output: html_document
---

```{r, message = FALSE, warning = FALSE}
# packages
library(tidyverse)
library(tidymodels)
library(tidytext)
library(keras)
library(tensorflow)

# data location
url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/labs/lab6-nn/data/claims-clean.csv'

# read in data
clean <- read_csv(url)
```

# ACTION DATA PARTITIONING

```{r}
# partition
set.seed(102722)
partitions <- clean %>%
  mutate(text_clean = str_trim(text_clean)) %>%
  filter(str_length(text_clean) > 5) %>%
  initial_split(prop = 0.8)
```

```{r}
train_dtm <- training(partitions) %>%
  unnest_tokens(output = 'token', 
                input = text_clean) %>%
  group_by(.id, bclass) %>%
  count(token) %>%
  bind_tf_idf(term = token, 
              document = .id, 
              n = n) %>%
  pivot_wider(id_cols = c(.id, bclass), 
              names_from = token, 
              values_from = tf_idf,
              values_fill = 0) %>%
  ungroup()
```

# Logistic Regression as NN

```{r}
# extract first ten features
x_train <- train_dtm %>%
  ungroup() %>%
  select(-.id, -bclass) %>%
  select(1:10) %>%
  as.matrix()

# extract labels and coerce to binary
y_train <- train_dtm %>% 
  pull(bclass) %>%
  factor() %>%
  as.numeric() - 1
```

```{r}
# specify model type
model <- keras_model_sequential(input_shape = 10)
```

```{r}
summary(model)
```

```{r}
# add output layer
model <- model %>% layer_dense(1) 
```


```{r}
summary(model)
```

```{r}
model <- model %>% 
  layer_activation(activation = 'sigmoid')
```

## Model Configuration

```{r}
model %>% compile(
  loss = 'binary_crossentropy',
  optimizer = optimizer_sgd(),
  metrics = 'binary_accuracy'
)
```

```{r}
# retrieve weights
get_weights(model)
```

```{r}
# evaluate on specified data
evaluate(model, x_train, y_train)
```

```{r}
# compute predictions
model(x_train) %>% head()
```

# ACTION CHECK FOR UNDERSTANDING

Discuss with your neighbor:

1. How many parameters does this model have?

This model has 11 parameters

2. Do the number of parameters match your expectations?

Yes since we have the first 10 tokens and 1 response class

3. Why will the parameter estimates not match the result of glm() ?

This will not match the result of glm() since we adjust the weights of the parameters in order to minimize our loss over epochs. our weights will be depend on our optimizer and how well the optimizer achieve the lowest loss

4. Would further training epochs improve the performance?

  In sgd the is no gaurentee because we are subsetting the data to comput the gradient; thus, the randomness of the data could cause the loss to increase from one epoch to the next epoch


# Single-layer network

```{r}
# store full DTM as a matrix
x_train <- train_dtm %>%
  select(-bclass, -.id) %>%
  as.matrix()
```

```{r}
model <- keras_model_sequential(input_shape = ncol(x_train)) %>%
  layer_dense(10) %>%
  layer_dense(1) %>%
  layer_activation(activation = 'sigmoid')

summary(model)
```

```{r}
model %>%
  compile(
    loss = 'binary_crossentropy',
    optimizer = optimizer_sgd(),
    metrics = 'binary_accuracy'
  )
```

```{r}
history <- model %>%
  fit(x = x_train,
      y = y_train,
      epochs = 50)

plot(history)
```

## Using adam instead of SGD

```{r}
# change the optimizer
model %>%
  compile(
    loss = 'binary_crossentropy',
    optimizer = 'adam',
    metrics = 'binary_accuracy'
  )

# re-train
history <- model %>%
  fit(x = x_train,
      y = y_train,
      epochs = 10)

plot(history)
```

# Validation Data

Perform cross-validation

```{r}
# redefine model
model <- keras_model_sequential(input_shape = ncol(x_train)) %>%
  layer_dense(10) %>%
  layer_dense(1) %>%
  layer_activation(activation = 'sigmoid')

model %>%
  compile(
    loss = 'binary_crossentropy',
    optimizer = 'adam',
    metrics = 'binary_accuracy'
  )

# train with validation split
history <- model %>%
  fit(x = x_train,
      y = y_train,
      epochs = 20,
      validation_split = 0.2)

plot(history)
```

# ACTION COMPUTE PREDICTIONS

```{r}
test_dtm <- testing(partitions) %>%
  unnest_tokens(output = 'token', 
                input = text_clean) %>%
  group_by(.id, bclass) %>%
  count(token) %>%
  bind_tf_idf(term = token, 
              document = .id, 
              n = n) %>%
  pivot_wider(id_cols = c(.id, bclass), 
              names_from = token, 
              values_from = tf_idf,
              values_fill = 0) %>%
  ungroup()
```

```{r}
# extract labels and coerce to binary
y_test <- train_dtm %>% 
  pull(bclass) %>%
  factor() %>%
  as.numeric() - 1
```

```{r}
# store full DTM as a matrix
x_test <- train_dtm %>%
  select(-bclass, -.id) %>%
  as.matrix()
```

```{r}
prediction <- model %>%
  predict(y = y_test, x = x_test, type = 'class')

prediction <- sapply(prediction,
      function(x) {ifelse(x>.5, '1', '0')}
)
```

```{r}
mean(prediction == y_test)
```

We get that there is a 0.938914 accuracy.
